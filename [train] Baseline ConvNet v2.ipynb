{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [train] Baseline ConvNet v2\n",
    "\n",
    "Un premier réseau convolutionnel dédié à la classification d'imagettes extraites d'images satellites. Entrainement sur un jeu généré à partir des imagettes du défi de l'IC (véhicules et fond) et de deux sous images de la Corse. Les imagettes de tests sont générées à partir de la grille aposée sur la troisième sous image de la Corse. On commence par spécifier les paramètres généraux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/CU02_classification\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/data/CU02_classification/\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/mnt/data/')\n",
    "dir_train = 'data/snapshots_48x48x1/12_48x48x1_2C_PNG_BASE+CORSE+DEC+ROT+FLIP/'\n",
    "dir_val = 'data/snapshots_48x48x1/03_48X48X1_2C_PNG_CORSE_TEST/'\n",
    "model_shortname = 'less_filters_444'\n",
    "current_notebook = 'notebooks/[train] Baseline ConvNet v2.ipynb'\n",
    "logpath = 'models/hypotheses_2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données / pré-processing\n",
    "\n",
    "Les données d'entrainement sont des images simple bande en nuances de gris de dimensions (48,48), également appelées imagettes ou snapshots. On utilise des générateurs pour alimenter automatiquement les algorithmes à partir de dossiers, sans charger simultanément toutes les données d'entrainement en mémoire.\n",
    "\n",
    "##### Cropping vs Downsampling : \n",
    "\n",
    "- On utilise la classe ImageDataGenerator de keras.preprocesssing.image légèrement adaptée pour éviter le rescaling automatique des imagettes en nuances de gris. On travaille sur les valeurs brutes des imagettes.\n",
    "\n",
    "- Les imagettes qui font plus de (48,48) pixels sont cropées à partir du centre. On préfère cette alternative plutôt que le sous échantillonnage car on souhaite conserver tous les détails des véhicules qui sont déjà très petits. Le classe ImageDataGenerator de Keras a du là aussi eere adaptée pour découper les images plutôt qu'en réduire la résolution.\n",
    "\n",
    "- Les véhicules n'étant pas systématiquement centré dans les imagettes, le découpage risque de supprimer certains véhicules des imagettes du jeu d'entrainement / de validation : vérifier l'impact. En terme de prédiction, le découpage des imagettes semble donner de meilleures performances que le downsampling. Les cartes de chaleurs présentent beaucoup plus de vrais positifs ET de faux positifs: on améliore le rappel mais on dégrade la précision. \n",
    "\n",
    "##### Autres paramètres\n",
    "\n",
    "- Normalisation des imagettes : l'opération semble plutôt introduire de la confusion dans la réflexion, on la neutralise pour le moment. La question de fond est de savoir sur quel périmètre il faut normaliser (epoch, batch, sample).\n",
    "\n",
    "- L'augmentation des données : idem, on neutralise jusqu'à être sur d'avoir un pipeline qui fonctionne jusqu'en prédiction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 119189 images belonging to 2 classes.\n",
      "Found 47817 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from pydrm.roim.keras_image_custom2 import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size = (48,48),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    color_mode = 'grayscale',\n",
    "    # shuffle = False\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dir_val,\n",
    "    target_size = (48,48),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary',\n",
    "    color_mode = 'grayscale',\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Classes imbalance\n",
    "\n",
    "Le jeu de test comprend 83% d'images de fond vs 17% d'images de voitures. L'accuracy de base ne doit donc pas tomber en dessous de 83%. Pour corriger ce déséquilibre on associe un poids plus important aux imagettes de véhicules. Attention à ne pas se tromper, on associe à la classe la moins fréquente le poids le plus élevé. On améliore encore sensiblement les résultats en précision / rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.44634991484113468, 1: 0.55365008515886538}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snapshots fond</th>\n",
       "      <th>snapshots vehicules</th>\n",
       "      <th>total</th>\n",
       "      <th>freqvoit</th>\n",
       "      <th>freqfond</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traning set</th>\n",
       "      <td>65989</td>\n",
       "      <td>53200</td>\n",
       "      <td>119189</td>\n",
       "      <td>0.446350</td>\n",
       "      <td>0.553650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set</th>\n",
       "      <td>46307</td>\n",
       "      <td>1510</td>\n",
       "      <td>47817</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>0.968421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                snapshots fond  snapshots vehicules   total  freqvoit  \\\n",
       "traning set              65989                53200  119189  0.446350   \n",
       "validation set           46307                 1510   47817  0.031579   \n",
       "\n",
       "                freqfond  \n",
       "traning set     0.553650  \n",
       "validation set  0.968421  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAI/CAYAAAAC42+qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNDm/VYJUQAQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c9fbe21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.DataFrame(index = ['traning set', 'validation set'])\n",
    "df['snapshots fond'] = [sum(1 - train_generator.classes), sum(1- val_generator.classes)]\n",
    "df['snapshots vehicules'] = [sum(train_generator.classes), sum(val_generator.classes)]\n",
    "df['total'] = df['snapshots fond'] + df['snapshots vehicules']\n",
    "df['freqvoit'] = df['snapshots vehicules'] / df['total']\n",
    "df['freqfond'] = df['snapshots fond'] / df['total']\n",
    "\n",
    "ax = df[['snapshots fond', 'snapshots vehicules']].plot(\n",
    "    kind = 'barh', \n",
    "    stacked = True, \n",
    "    figsize = (10,10),\n",
    ")\n",
    "\n",
    "ax.title.set_fontsize(15)\n",
    "ax.yaxis.label.set_fontsize(20)\n",
    "\n",
    "vals = df[['freqfond', 'freqvoit']].T.stack().values\n",
    "\n",
    "for p, val in zip(ax.patches, vals):\n",
    "    ax.annotate(str(round(val, 4)), \n",
    "                (p.get_x() + p.get_width() * 0.4, p.get_y() + p.get_height() * 0.4),\n",
    "               )\n",
    "\n",
    "class_weight = {\n",
    "    0 : sum(train_generator.classes) / train_generator.samples,\n",
    "    1 : sum(1 - train_generator.classes) / train_generator.samples\n",
    "}\n",
    "\n",
    "print(class_weight)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Définition du ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "\n",
    "def simple_image_clf() :\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layers\n",
    "\n",
    "    model.add(Conv2D(filters = 4, kernel_size = (4, 4), input_shape = (48, 48, 1), strides = (1,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 4, kernel_size = (4, 4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters = 4, kernel_size = (4, 4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    # The binary classifier : 2 dense layers + a sigmoid top\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units = 16))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units = 16))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(units = 1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = simple_image_clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement du modèle\n",
    "\n",
    "#### Mesures de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/hypotheses_2//run-20171012-1434-less_filters_444/\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d-%H%M\")\n",
    "logdir = \"{}/run-{}-{}/\".format(logpath, now, model_shortname)\n",
    "print(logdir)\n",
    "\n",
    "from sklearn import metrics\n",
    "from pydrm.callbacks import Metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import imp\n",
    "import pydrm.callbacks as cb\n",
    "cb = imp.reload(cb)\n",
    "\n",
    "checkpt_loss = ModelCheckpoint(filepath = logdir + \"checkpt_loss.h5\", \n",
    "                               monitor = 'loss', \n",
    "                               save_best_only = True)\n",
    "\n",
    "checkpt_val_acc = ModelCheckpoint(filepath = logdir + \"checkpt_val_acc.h5\", \n",
    "                               monitor = 'val_accuracy', \n",
    "                               save_best_only = True)\n",
    "\n",
    "metrics = {\n",
    "    'val_accuracy' : metrics.accuracy_score,\n",
    "    'val_precision' : metrics.precision_score,\n",
    "    'val_recall' : metrics.recall_score,\n",
    "    'val_f1' : metrics.f1_score,\n",
    "    'val_kappa' : metrics.cohen_kappa_score\n",
    "}\n",
    "\n",
    "val_metrics = cb.Metrics(val_generator, threshold = 0.5, log_dir = logdir, metrics = metrics)\n",
    "#val_metrics = cb.Metrics(dir_val, threshold = 0.5, log_dir = logdir, metrics = metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de perte et optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adadelta\n",
    "from keras.metrics import binary_crossentropy, binary_accuracy\n",
    "\n",
    "model.compile(loss = binary_crossentropy,\n",
    "              optimizer = Adadelta(lr = 1.0, rho = 0.95),\n",
    "              metrics = [binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancement du run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set info : 3725 steps * 32 images/batch, -11 samples left out\n",
      "Validation set info : 1495 steps * 32 images/batch, -23 samples left out\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0 is illegal; using conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0 is illegal; using conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/gamma:0 is illegal; using batch_normalization_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/beta:0 is illegal; using batch_normalization_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/moving_mean:0 is illegal; using batch_normalization_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/moving_variance:0 is illegal; using batch_normalization_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/kernel:0 is illegal; using conv2d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/bias:0 is illegal; using conv2d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/gamma:0 is illegal; using batch_normalization_2/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/beta:0 is illegal; using batch_normalization_2/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/moving_mean:0 is illegal; using batch_normalization_2/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/moving_variance:0 is illegal; using batch_normalization_2/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/kernel:0 is illegal; using conv2d_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/bias:0 is illegal; using conv2d_3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/gamma:0 is illegal; using batch_normalization_3/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/beta:0 is illegal; using batch_normalization_3/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/moving_mean:0 is illegal; using batch_normalization_3/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/moving_variance:0 is illegal; using batch_normalization_3/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/kernel:0 is illegal; using dense_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_1/bias:0 is illegal; using dense_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/kernel:0 is illegal; using dense_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_2/bias:0 is illegal; using dense_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/kernel:0 is illegal; using dense_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name dense_3/bias:0 is illegal; using dense_3/bias_0 instead.\n",
      "Epoch 1/20\n",
      "1491/1495 [============================>.] - ETA: 0s[[38773  7534]\n",
      " [  147  1363]]\n",
      "{'val_precision': 0.15319770709227828, 'loss': 0.16212437848310915, 'val_recall': 0.90264900662251657, 'binary_accuracy': 0.87485422312611749, 'val_accuracy': 0.83936675241023062, 'val_f1': 0.26193907946574418, 'val_kappa': 0.21981399247963584}\n",
      "3725/3725 [==============================] - 120s - loss: 0.1621 - binary_accuracy: 0.8749   \n",
      "Epoch 2/20\n",
      "1495/1495 [==============================] - 15s    \n",
      "[[43055  3252]\n",
      " [  456  1054]]\n",
      "{'val_precision': 0.24477473293079424, 'loss': 0.1117509297038206, 'val_recall': 0.69801324503311257, 'binary_accuracy': 0.9163093909697877, 'val_accuracy': 0.92245435723696589, 'val_f1': 0.36244841815680884, 'val_kappa': 0.33117413944177465}\n",
      "3725/3725 [==============================] - 121s - loss: 0.1118 - binary_accuracy: 0.9163   \n",
      "Epoch 3/20\n",
      "1491/1495 [============================>.] - ETA: 0s[[43628  2679]\n",
      " [  482  1028]]\n",
      "{'val_precision': 0.27731319125977882, 'loss': 0.09464398293261779, 'val_recall': 0.68079470198675496, 'binary_accuracy': 0.92881054459923662, 'val_accuracy': 0.93389380345902084, 'val_f1': 0.394096223883458, 'val_kappa': 0.36562731368105506}\n",
      "3725/3725 [==============================] - 119s - loss: 0.0947 - binary_accuracy: 0.9288   \n",
      "Epoch 4/20\n",
      "1490/1495 [============================>.] - ETA: 0s[[42405  3902]\n",
      " [  393  1117]]\n",
      "{'val_precision': 0.22255429368400079, 'loss': 0.086509242637844014, 'val_recall': 0.73973509933774839, 'binary_accuracy': 0.93565681396823197, 'val_accuracy': 0.91017838843925802, 'val_f1': 0.34216572216265889, 'val_kappa': 0.30859768282980982}\n",
      "3725/3725 [==============================] - 119s - loss: 0.0865 - binary_accuracy: 0.9357   \n",
      "Epoch 5/20\n",
      "1494/1495 [============================>.] - ETA: 0s[[43753  2554]\n",
      " [  527   983]]\n",
      "{'val_precision': 0.27791914051456035, 'loss': 0.080657673420021642, 'val_recall': 0.65099337748344366, 'binary_accuracy': 0.93846747602597225, 'val_accuracy': 0.93556684861032691, 'val_f1': 0.38953833960768774, 'val_kappa': 0.36126704498164908}\n",
      "3725/3725 [==============================] - 118s - loss: 0.0807 - binary_accuracy: 0.9385   \n",
      "Epoch 6/20\n",
      "1494/1495 [============================>.] - ETA: 0s[[39830  6477]\n",
      " [  217  1293]]\n",
      "{'val_precision': 0.1664092664092664, 'loss': 0.078340563837277763, 'val_recall': 0.85629139072847682, 'binary_accuracy': 0.94077473592361716, 'val_accuracy': 0.86000794696446869, 'val_f1': 0.27866379310344824, 'val_kappa': 0.23838923988015881}\n",
      "3725/3725 [==============================] - 119s - loss: 0.0783 - binary_accuracy: 0.9408   \n",
      "Epoch 7/20\n",
      "1492/1495 [============================>.] - ETA: 0s[[40368  5939]\n",
      " [  300  1210]]\n",
      "{'val_precision': 0.16925444118058469, 'loss': 0.07631374632410684, 'val_recall': 0.80132450331125826, 'binary_accuracy': 0.94231011251038266, 'val_accuracy': 0.86952339126252165, 'val_f1': 0.27947799976902649, 'val_kappa': 0.23984043741733474}\n",
      "3725/3725 [==============================] - 110s - loss: 0.0763 - binary_accuracy: 0.9423   \n",
      "Epoch 8/20\n",
      "1489/1495 [============================>.] - ETA: 0s[[44420  1887]\n",
      " [  668   842]]\n",
      "{'val_precision': 0.30853792598021251, 'loss': 0.074058804668880623, 'val_recall': 0.5576158940397351, 'binary_accuracy': 0.94439084143720986, 'val_accuracy': 0.946567120480164, 'val_f1': 0.39726350554376028, 'val_kappa': 0.37171770247364011}\n",
      "3725/3725 [==============================] - 107s - loss: 0.0741 - binary_accuracy: 0.9444   \n",
      "Epoch 9/20\n",
      "1491/1495 [============================>.] - ETA: 0s[[40733  5574]\n",
      " [  263  1247]]\n",
      "{'val_precision': 0.18281776865562235, 'loss': 0.073857321449045513, 'val_recall': 0.82582781456953647, 'binary_accuracy': 0.94487746352431856, 'val_accuracy': 0.87793044314783442, 'val_f1': 0.29936382187012361, 'val_kappa': 0.26115822622561291}\n",
      "3725/3725 [==============================] - 108s - loss: 0.0739 - binary_accuracy: 0.9449   \n",
      "Epoch 10/20\n",
      "1493/1495 [============================>.] - ETA: 0s[[42848  3459]\n",
      " [  370  1140]]\n",
      "{'val_precision': 0.24787997390737115, 'loss': 0.072074126302588346, 'val_recall': 0.75496688741721851, 'binary_accuracy': 0.9462198692852396, 'val_accuracy': 0.91992387644561557, 'val_f1': 0.37321983958094607, 'val_kappa': 0.34193100921569364}\n",
      "3725/3725 [==============================] - 114s - loss: 0.0721 - binary_accuracy: 0.9462   \n",
      "Epoch 11/20\n",
      "1490/1495 [============================>.] - ETA: 0s[[43416  2891]\n",
      " [  472  1038]]\n",
      "{'val_precision': 0.26418936116060066, 'loss': 0.070147275484482699, 'val_recall': 0.68741721854304638, 'binary_accuracy': 0.94739447432329504, 'val_accuracy': 0.92966936445197312, 'val_f1': 0.38168781025923887, 'val_kappa': 0.35212977173948357}\n",
      "3725/3725 [==============================] - 108s - loss: 0.0701 - binary_accuracy: 0.9474   \n",
      "Epoch 12/20\n",
      "1492/1495 [============================>.] - ETA: 0s[[40390  5917]\n",
      " [  252  1258]]\n",
      "{'val_precision': 0.17533101045296168, 'loss': 0.069690543271788169, 'val_recall': 0.83311258278145695, 'binary_accuracy': 0.94868653986575613, 'val_accuracy': 0.87098730576991445, 'val_f1': 0.28969487622337359, 'val_kappa': 0.25059329931754726}\n",
      "3725/3725 [==============================] - 105s - loss: 0.0697 - binary_accuracy: 0.9487   \n",
      "Epoch 13/20\n",
      "1494/1495 [============================>.] - ETA: 0s[[37765  8542]\n",
      " [  161  1349]]\n",
      "{'val_precision': 0.13638661409362046, 'loss': 0.070429711347655147, 'val_recall': 0.8933774834437086, 'binary_accuracy': 0.94783914622993737, 'val_accuracy': 0.8179936006022962, 'val_f1': 0.23664590825366197, 'val_kappa': 0.19239514188335083}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725/3725 [==============================] - 103s - loss: 0.0704 - binary_accuracy: 0.9478   \n",
      "Epoch 14/20\n",
      "1490/1495 [============================>.] - ETA: 0s[[40505  5802]\n",
      " [  264  1246]]\n",
      "{'val_precision': 0.17678774120317819, 'loss': 0.069564097609255082, 'val_recall': 0.8251655629139073, 'binary_accuracy': 0.94803211705828228, 'val_accuracy': 0.87314135140222093, 'val_f1': 0.29118953026408034, 'val_kappa': 0.25229878012468565}\n",
      "3725/3725 [==============================] - 104s - loss: 0.0696 - binary_accuracy: 0.9480   \n",
      "Epoch 15/20\n",
      "1490/1495 [============================>.] - ETA: 0s[[28051 18256]\n",
      " [   55  1455]]\n",
      "{'val_precision': 0.073816650601187153, 'loss': 0.069431126183717537, 'val_recall': 0.96357615894039739, 'binary_accuracy': 0.94902214130548623, 'val_accuracy': 0.61706087793044317, 'val_f1': 0.13712831629046698, 'val_kappa': 0.08335476546664633}\n",
      "3725/3725 [==============================] - 103s - loss: 0.0694 - binary_accuracy: 0.9490   \n",
      "Epoch 16/20\n",
      "1491/1495 [============================>.] - ETA: 0s[[38826  7481]\n",
      " [  166  1344]]\n",
      "{'val_precision': 0.15229461756373938, 'loss': 0.069317601720261593, 'val_recall': 0.89006622516556289, 'binary_accuracy': 0.94955910360855444, 'val_accuracy': 0.84007779659953574, 'val_f1': 0.26008708272859216, 'val_kappa': 0.21790907138414939}\n",
      "3725/3725 [==============================] - 105s - loss: 0.0693 - binary_accuracy: 0.9496   \n",
      "Epoch 17/20\n",
      "1492/1495 [============================>.] - ETA: 0s[[44818  1489]\n",
      " [  747   763]]\n",
      "{'val_precision': 0.33880994671403197, 'loss': 0.068282012799744343, 'val_recall': 0.5052980132450331, 'binary_accuracy': 0.94972690433041995, 'val_accuracy': 0.9532383880209967, 'val_f1': 0.40563530037214246, 'val_kappa': 0.38228109441270508}\n",
      "3725/3725 [==============================] - 115s - loss: 0.0683 - binary_accuracy: 0.9497   \n",
      "Epoch 18/20\n",
      "1490/1495 [============================>.] - ETA: 0s[[42815  3492]\n",
      " [  367  1143]]\n",
      "{'val_precision': 0.24660194174757283, 'loss': 0.068679175289075897, 'val_recall': 0.75695364238410601, 'binary_accuracy': 0.94960944382501411, 'val_accuracy': 0.9192964845138758, 'val_f1': 0.37200976403580149, 'val_kappa': 0.34059720995842002}\n",
      "3725/3725 [==============================] - 116s - loss: 0.0687 - binary_accuracy: 0.9496   \n",
      "Epoch 19/20\n",
      "1493/1495 [============================>.] - ETA: 0s[[43396  2911]\n",
      " [  539   971]]\n",
      "{'val_precision': 0.25012879958784134, 'loss': 0.067716935742639428, 'val_recall': 0.64304635761589402, 'binary_accuracy': 0.95068336843215062, 'val_accuracy': 0.92784992784992781, 'val_f1': 0.36016320474777447, 'val_kappa': 0.32968354270522482}\n",
      "3725/3725 [==============================] - 111s - loss: 0.0677 - binary_accuracy: 0.9507   \n",
      "Epoch 20/20\n",
      "1493/1495 [============================>.] - ETA: 0s[[37613  8694]\n",
      " [  160  1350]]\n",
      "{'val_precision': 0.13440860215053763, 'loss': 0.066993390131451683, 'val_recall': 0.89403973509933776, 'binary_accuracy': 0.95096862965642137, 'val_accuracy': 0.81483572787920611, 'val_f1': 0.23368530379089492, 'val_kappa': 0.18916789313694105}\n",
      "3725/3725 [==============================] - 113s - loss: 0.0670 - binary_accuracy: 0.9510   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c707e4358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, shutil\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "shutil.copy(current_notebook, logdir)\n",
    "with open(logdir + 'model_architecture.json', 'w') as outfile:\n",
    "    outfile.write(model.to_json())\n",
    "    \n",
    "steps_train = train_generator.samples // train_generator.batch_size + 1\n",
    "\n",
    "print('Training set info : {} steps * {} images/batch, {} samples left out'.format(steps_train,\n",
    "                                                                                 train_generator.batch_size,\n",
    "                                                                                 train_generator.samples - (train_generator.batch_size * steps_train)))\n",
    "\n",
    "\n",
    "print('Validation set info : {} steps * {} images/batch, {} samples left out'.format(val_metrics.steps,\n",
    "                                                                                 val_metrics.val_generator.batch_size,\n",
    "                                                                                 val_metrics.val_generator.samples - (val_metrics.val_generator.batch_size * val_metrics.steps)))\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = steps_train,\n",
    "    epochs = 20,\n",
    "    callbacks = [checkpt_loss, val_metrics, checkpt_val_acc],\n",
    "    class_weight = class_weight\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
