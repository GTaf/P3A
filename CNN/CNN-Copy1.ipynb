{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "import os\n",
    "from osgeo import gdal\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_classes = 2\n",
    "epochs = 5\n",
    "\n",
    "img_rows, img_cols = 81, 81\n",
    "\n",
    "array = []\n",
    "et = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=(81,81,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(32, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, (2, 2)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    " \n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization(axis=-1)\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# \n",
    "\n",
    "    model.add(Flatten())\n",
    "#    # Fully connected layer\n",
    "#\n",
    "    BatchNormalization()\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    BatchNormalization()\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    \n",
    "    sgd = keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',#keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "model.load_weights(\"weights.best94.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"x.npy\")\n",
    "y_train = np.load(\"y.npy\")\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i][0] < y_pred[i][1]:\n",
    "        y_pred[i]=[0,1]\n",
    "    else:\n",
    "        y_pred[i]=[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_test = []\n",
    "yy_pred = []\n",
    "for i in range(len(y_train)):\n",
    "    if y_pred[i][0] == 0:\n",
    "        yy_pred.append(1)\n",
    "    else:\n",
    "        yy_pred.append(0)\n",
    "    \n",
    "    if y_train[i][0] == 0:\n",
    "        yy_test.append(1)\n",
    "    else:\n",
    "        yy_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1707,  165],\n",
       "       [  64, 1808]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yy_test, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965811965812\n",
      "0.916371008616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score,precision_score\n",
    "print(recall_score(yy_test,yy_pred))\n",
    "print(precision_score(yy_test,yy_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_ever.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
